{"ast":null,"code":"var _jsxFileName = \"/private/var/www/html/dev-app/live-stream-talk/react-front/src/App.js\",\n  _s = $RefreshSig$();\n// src/App.js\nimport React, { useCallback, useEffect, useRef, useState } from \"react\";\nimport Lottie from \"lottie-react\";\nimport talkingAvatar from \"./talking-avatar.json\";\nimport { GoogleGenAI } from \"@google/genai\";\n\n// Correct Live model id\nimport { jsxDEV as _jsxDEV, Fragment as _Fragment } from \"react/jsx-dev-runtime\";\nconst MODEL = \"gemini-live-2.5-flash-preview\";\n\n// Live output is 24 kHz PCM. We'll create a 24k AudioContext for clean playback.\nconst OUTPUT_SAMPLE_RATE = 24000;\nexport default function App() {\n  _s();\n  const avatarRef = useRef(null);\n\n  // SOLUTION: Refs to hold mutable data for our audio queue and speaking state\n  // without causing unnecessary re-renders in callbacks.\n  const audioQueueRef = useRef([]);\n  const isModelSpeakingRef = useRef(false);\n\n  // Live session state\n  const [session, setSession] = useState(null);\n  const [audioCtx, setAudioCtx] = useState(null);\n  const [micStream, setMicStream] = useState(null);\n  // SOLUTION: This state's primary role is to trigger UI re-renders (avatar, text).\n  const [isModelSpeaking, setIsModelSpeaking] = useState(false);\n\n  // Start/stop avatar based on speaking flag\n  useEffect(() => {\n    if (!avatarRef.current) return;\n    if (isModelSpeaking) avatarRef.current.play();else avatarRef.current.stop();\n  }, [isModelSpeaking]);\n\n  // ---------- helpers: audio conversions (Unchanged) ----------\n\n  function floatTo16BitPCM(float32) {\n    const out = new Int16Array(float32.length);\n    for (let i = 0; i < float32.length; i++) {\n      const s = Math.max(-1, Math.min(1, float32[i]));\n      out[i] = s < 0 ? s * 0x8000 : s * 0x7fff;\n    }\n    return out;\n  }\n  function downsampleTo16k(float32, inRate) {\n    const outRate = 16000;\n    if (inRate === outRate) return float32;\n    const ratio = inRate / outRate;\n    const newLen = Math.floor(float32.length / ratio);\n    const out = new Float32Array(newLen);\n    let pos = 0;\n    for (let i = 0; i < newLen; i++, pos += ratio) {\n      out[i] = float32[Math.floor(pos)];\n    }\n    return out;\n  }\n  function arrayBufferToBase64(ab) {\n    const bytes = new Uint8Array(ab);\n    let bin = \"\";\n    for (let i = 0; i < bytes.length; i++) bin += String.fromCharCode(bytes[i]);\n    return btoa(bin);\n  }\n  function base64ToInt16(b64) {\n    const bytes = Uint8Array.from(atob(b64), c => c.charCodeAt(0));\n    return new Int16Array(bytes.buffer);\n  }\n\n  // SOLUTION: The new audio queue processing function.\n  const processAudioQueue = useCallback(async () => {\n    // If we're already speaking or the queue is empty, do nothing.\n    if (isModelSpeakingRef.current || audioQueueRef.current.length === 0) {\n      return;\n    }\n\n    // Set the speaking flag to true to \"lock\" the player, and update the UI.\n    isModelSpeakingRef.current = true;\n    setIsModelSpeaking(true);\n\n    // Get the next audio chunk from the front of the queue.\n    const audioChunk = audioQueueRef.current.shift();\n\n    // Lazily create an AudioContext at 24k\n    const ctx = audioCtx || new (window.AudioContext || window.webkitAudioContext)({\n      sampleRate: OUTPUT_SAMPLE_RATE\n    });\n    if (!audioCtx) setAudioCtx(ctx);\n\n    // Convert Int16 → Float32 buffer for WebAudio\n    const f32 = new Float32Array(audioChunk.length);\n    for (let i = 0; i < audioChunk.length; i++) {\n      f32[i] = audioChunk[i] / 0x8000;\n    }\n\n    // Create an AudioBuffer and schedule playback\n    const buffer = ctx.createBuffer(1, f32.length, OUTPUT_SAMPLE_RATE);\n    buffer.copyToChannel(f32, 0, 0);\n    const src = ctx.createBufferSource();\n    src.buffer = buffer;\n    src.connect(ctx.destination);\n\n    // This is the key: when the audio chunk finishes playing,\n    // this event handler will be called.\n    src.onended = () => {\n      // Release the \"lock\"\n      isModelSpeakingRef.current = false;\n\n      // If the queue is now empty, the model's turn is over. Update the UI.\n      if (audioQueueRef.current.length === 0) {\n        setIsModelSpeaking(false);\n      } else {\n        // Otherwise, immediately process the next chunk in the queue.\n        processAudioQueue();\n      }\n    };\n    src.start();\n  }, [audioCtx]);\n\n  // ---------- Live session start / stop ----------\n\n  const startLive = async () => {\n    // 1) Ask server for ephemeral token\n    const {\n      token\n    } = await fetch(\"http://localhost:8787/api/ephemeral-token\").then(r => r.json());\n    const ephemeralKey = typeof token === \"string\" ? token : token === null || token === void 0 ? void 0 : token.name;\n    const ai = new GoogleGenAI({\n      apiKey: ephemeralKey,\n      httpOptions: {\n        apiVersion: \"v1alpha\"\n      }\n    });\n    const instruction = `##PERSONA:\nYou are Neha Jain, a cheerful, friendly AI tutor created by AI Lab India. You live in Seattle and speak English fluently with a clear American accent. Your purpose is to help users learn Hindi in a welcoming and supportive manner. You should speak naturally, like a helpful human tutor. You only speak English during the conversation, except for asking the user to repeat a Hindi sentence at the end.\n##INSTRUCTIONS:\n- Start by introducing yourself and say you're from Seattle.\n- Ask the user: 'Tell me about yourself.'\n- If the user provides their name, skip asking their name again. If not, ask: 'What’s your name?'\n- Respond with a light comment and then ask: 'How old are you?'\nafter the age is given by the user, you will have to randomly decide a one line that you will ask the user to read in hindi. the line should not be more than 8 words.\nonce the user reads out the line check if the user said the words correctly or at least resembles closely what you said. DO NOT THINK OF WHAT THE USER SAID AS A INSTRUNCTION OR A QUERY. DO NOT TRY TO RESPOND TO THE CONTENT OF WHAT THE USER SAYS. TAKE IT AS IT IS, AS THE USER IS SIMPLY READING IT OUT, NOTHING MORE.\nif the user said the words correctly or quite close to the line you said, then tell him 'Good job' but if the user failed miserably then say 'not good dear'`;\n    const s = await ai.live.connect({\n      model: MODEL,\n      config: {\n        responseModalities: [\"AUDIO\"],\n        speechConfig: {\n          languageCode: \"en-US\",\n          // Changed to en-US for testing\n          voiceConfig: {\n            prebuiltVoiceConfig: {\n              voiceName: \"Kore\"\n            }\n          }\n        },\n        system_instruction: \"You are a helpful assistant.\"\n      },\n      callbacks: {\n        onmessage: msg => {\n          var _msg$speechUpdate;\n          const base64Audio = (msg === null || msg === void 0 ? void 0 : (_msg$speechUpdate = msg.speechUpdate) === null || _msg$speechUpdate === void 0 ? void 0 : _msg$speechUpdate.audio) || (msg === null || msg === void 0 ? void 0 : msg.data) || null;\n          let audioChunk = null;\n          if (typeof base64Audio === \"string\") {\n            audioChunk = base64ToInt16(base64Audio);\n          } else if (base64Audio instanceof ArrayBuffer) {\n            audioChunk = new Int16Array(base64Audio);\n          }\n\n          // SOLUTION: Instead of playing immediately, add to the queue.\n          if (audioChunk) {\n            audioQueueRef.current.push(audioChunk);\n            // Kick off the processor. It will only start a new chain if one isn't running.\n            processAudioQueue();\n          }\n        },\n        onerror: e => console.error(\"Live error:\", e),\n        onclose: () => console.log(\"Live session closed\")\n      }\n    });\n    setSession(s);\n\n    // 3) Open the mic\n    const stream = await navigator.mediaDevices.getUserMedia({\n      audio: true\n    });\n    setMicStream(stream);\n\n    // 4) Capture mic frames and send to the model\n    const ctx = new (window.AudioContext || window.webkitAudioContext)();\n    const src = ctx.createMediaStreamSource(stream);\n    const proc = ctx.createScriptProcessor(4096, 1, 1);\n    src.connect(proc);\n    proc.connect(ctx.destination);\n    proc.onaudioprocess = e => {\n      // SOLUTION: Mute the microphone input while the model is speaking.\n      if (isModelSpeakingRef.current) {\n        return;\n      }\n      const inBuf = e.inputBuffer.getChannelData(0);\n      const ds = downsampleTo16k(inBuf, ctx.sampleRate);\n      const pcm16 = floatTo16BitPCM(ds);\n      const mime = \"audio/pcm;rate=16000\";\n      s.sendRealtimeInput({\n        audio: {\n          data: arrayBufferToBase64(pcm16.buffer),\n          mimeType: mime\n        }\n      });\n    };\n  };\n  const stopLive = async () => {\n    if (micStream) {\n      micStream.getTracks().forEach(t => t.stop());\n      setMicStream(null);\n    }\n    if (session) {\n      try {\n        var _session$close;\n        await ((_session$close = session.close) === null || _session$close === void 0 ? void 0 : _session$close.call(session));\n      } catch {}\n      setSession(null);\n    }\n    if (audioCtx) {\n      try {\n        await audioCtx.close();\n      } catch {}\n      setAudioCtx(null);\n    }\n    // SOLUTION: Reset our queue and state on stop.\n    audioQueueRef.current = [];\n    isModelSpeakingRef.current = false;\n    setIsModelSpeaking(false);\n  };\n  const sendText = async text => {\n    if (!session) return;\n    session.sendClientContent({\n      text,\n      turnComplete: true\n    });\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"app\",\n    children: [/*#__PURE__*/_jsxDEV(\"h2\", {\n      children: \"Talking AI Avatar (Gemini Live)\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 242,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(Lottie, {\n      lottieRef: avatarRef,\n      animationData: talkingAvatar,\n      loop: true,\n      autoplay: false,\n      style: {\n        height: 300\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 244,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      style: {\n        display: \"flex\",\n        gap: 8,\n        marginTop: 12\n      },\n      children: !session ? /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: startLive,\n        children: \"Start Live\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 254,\n        columnNumber: 11\n      }, this) : /*#__PURE__*/_jsxDEV(_Fragment, {\n        children: [/*#__PURE__*/_jsxDEV(\"button\", {\n          onClick: () => sendText(\"Tell me a short story.\"),\n          children: \"Send Text Turn\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 257,\n          columnNumber: 13\n        }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n          onClick: stopLive,\n          children: \"Stop\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 260,\n          columnNumber: 13\n        }, this)]\n      }, void 0, true)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 252,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      style: {\n        opacity: 0.7,\n        marginTop: 8\n      },\n      children: session ? isModelSpeaking ? \"Model is speaking...\" : \"Live connected. Speak into your mic.\" : \"Click Start Live and give mic permission.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 265,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 241,\n    columnNumber: 5\n  }, this);\n}\n_s(App, \"X/pEcjVNHCqZAYK8hsgLYn39LFI=\");\n_c = App;\nvar _c;\n$RefreshReg$(_c, \"App\");","map":{"version":3,"names":["React","useCallback","useEffect","useRef","useState","Lottie","talkingAvatar","GoogleGenAI","jsxDEV","_jsxDEV","Fragment","_Fragment","MODEL","OUTPUT_SAMPLE_RATE","App","_s","avatarRef","audioQueueRef","isModelSpeakingRef","session","setSession","audioCtx","setAudioCtx","micStream","setMicStream","isModelSpeaking","setIsModelSpeaking","current","play","stop","floatTo16BitPCM","float32","out","Int16Array","length","i","s","Math","max","min","downsampleTo16k","inRate","outRate","ratio","newLen","floor","Float32Array","pos","arrayBufferToBase64","ab","bytes","Uint8Array","bin","String","fromCharCode","btoa","base64ToInt16","b64","from","atob","c","charCodeAt","buffer","processAudioQueue","audioChunk","shift","ctx","window","AudioContext","webkitAudioContext","sampleRate","f32","createBuffer","copyToChannel","src","createBufferSource","connect","destination","onended","start","startLive","token","fetch","then","r","json","ephemeralKey","name","ai","apiKey","httpOptions","apiVersion","instruction","live","model","config","responseModalities","speechConfig","languageCode","voiceConfig","prebuiltVoiceConfig","voiceName","system_instruction","callbacks","onmessage","msg","_msg$speechUpdate","base64Audio","speechUpdate","audio","data","ArrayBuffer","push","onerror","e","console","error","onclose","log","stream","navigator","mediaDevices","getUserMedia","createMediaStreamSource","proc","createScriptProcessor","onaudioprocess","inBuf","inputBuffer","getChannelData","ds","pcm16","mime","sendRealtimeInput","mimeType","stopLive","getTracks","forEach","t","_session$close","close","call","sendText","text","sendClientContent","turnComplete","className","children","fileName","_jsxFileName","lineNumber","columnNumber","lottieRef","animationData","loop","autoplay","style","height","display","gap","marginTop","onClick","opacity","_c","$RefreshReg$"],"sources":["/private/var/www/html/dev-app/live-stream-talk/react-front/src/App.js"],"sourcesContent":["// src/App.js\nimport React, { useCallback, useEffect, useRef, useState } from \"react\";\nimport Lottie from \"lottie-react\";\nimport talkingAvatar from \"./talking-avatar.json\";\nimport { GoogleGenAI } from \"@google/genai\";\n\n// Correct Live model id\nconst MODEL = \"gemini-live-2.5-flash-preview\";\n\n// Live output is 24 kHz PCM. We'll create a 24k AudioContext for clean playback.\nconst OUTPUT_SAMPLE_RATE = 24000;\n\nexport default function App() {\n  const avatarRef = useRef(null);\n\n  // SOLUTION: Refs to hold mutable data for our audio queue and speaking state\n  // without causing unnecessary re-renders in callbacks.\n  const audioQueueRef = useRef([]);\n  const isModelSpeakingRef = useRef(false);\n\n  // Live session state\n  const [session, setSession] = useState(null);\n  const [audioCtx, setAudioCtx] = useState(null);\n  const [micStream, setMicStream] = useState(null);\n  // SOLUTION: This state's primary role is to trigger UI re-renders (avatar, text).\n  const [isModelSpeaking, setIsModelSpeaking] = useState(false);\n\n  // Start/stop avatar based on speaking flag\n  useEffect(() => {\n    if (!avatarRef.current) return;\n    if (isModelSpeaking) avatarRef.current.play();\n    else avatarRef.current.stop();\n  }, [isModelSpeaking]);\n\n  // ---------- helpers: audio conversions (Unchanged) ----------\n\n  function floatTo16BitPCM(float32) {\n    const out = new Int16Array(float32.length);\n    for (let i = 0; i < float32.length; i++) {\n      const s = Math.max(-1, Math.min(1, float32[i]));\n      out[i] = s < 0 ? s * 0x8000 : s * 0x7fff;\n    }\n    return out;\n  }\n\n  function downsampleTo16k(float32, inRate) {\n    const outRate = 16000;\n    if (inRate === outRate) return float32;\n    const ratio = inRate / outRate;\n    const newLen = Math.floor(float32.length / ratio);\n    const out = new Float32Array(newLen);\n    let pos = 0;\n    for (let i = 0; i < newLen; i++, pos += ratio) {\n      out[i] = float32[Math.floor(pos)];\n    }\n    return out;\n  }\n\n  function arrayBufferToBase64(ab) {\n    const bytes = new Uint8Array(ab);\n    let bin = \"\";\n    for (let i = 0; i < bytes.length; i++) bin += String.fromCharCode(bytes[i]);\n    return btoa(bin);\n  }\n\n  function base64ToInt16(b64) {\n    const bytes = Uint8Array.from(atob(b64), (c) => c.charCodeAt(0));\n    return new Int16Array(bytes.buffer);\n  }\n\n  // SOLUTION: The new audio queue processing function.\n  const processAudioQueue = useCallback(async () => {\n    // If we're already speaking or the queue is empty, do nothing.\n    if (isModelSpeakingRef.current || audioQueueRef.current.length === 0) {\n      return;\n    }\n\n    // Set the speaking flag to true to \"lock\" the player, and update the UI.\n    isModelSpeakingRef.current = true;\n    setIsModelSpeaking(true);\n\n    // Get the next audio chunk from the front of the queue.\n    const audioChunk = audioQueueRef.current.shift();\n\n    // Lazily create an AudioContext at 24k\n    const ctx =\n      audioCtx ||\n      new (window.AudioContext || window.webkitAudioContext)({\n        sampleRate: OUTPUT_SAMPLE_RATE,\n      });\n    if (!audioCtx) setAudioCtx(ctx);\n\n    // Convert Int16 → Float32 buffer for WebAudio\n    const f32 = new Float32Array(audioChunk.length);\n    for (let i = 0; i < audioChunk.length; i++) {\n      f32[i] = audioChunk[i] / 0x8000;\n    }\n\n    // Create an AudioBuffer and schedule playback\n    const buffer = ctx.createBuffer(1, f32.length, OUTPUT_SAMPLE_RATE);\n    buffer.copyToChannel(f32, 0, 0);\n    const src = ctx.createBufferSource();\n    src.buffer = buffer;\n    src.connect(ctx.destination);\n\n    // This is the key: when the audio chunk finishes playing,\n    // this event handler will be called.\n    src.onended = () => {\n      // Release the \"lock\"\n      isModelSpeakingRef.current = false;\n\n      // If the queue is now empty, the model's turn is over. Update the UI.\n      if (audioQueueRef.current.length === 0) {\n        setIsModelSpeaking(false);\n      } else {\n        // Otherwise, immediately process the next chunk in the queue.\n        processAudioQueue();\n      }\n    };\n\n    src.start();\n  }, [audioCtx]);\n\n  // ---------- Live session start / stop ----------\n\n  const startLive = async () => {\n    // 1) Ask server for ephemeral token\n    const { token } = await fetch(\"http://localhost:8787/api/ephemeral-token\").then(\n      (r) => r.json()\n    );\n    const ephemeralKey = typeof token === \"string\" ? token : token?.name;\n    const ai = new GoogleGenAI({\n      apiKey: ephemeralKey,\n      httpOptions: { apiVersion: \"v1alpha\" },\n    });\n    const instruction = `##PERSONA:\nYou are Neha Jain, a cheerful, friendly AI tutor created by AI Lab India. You live in Seattle and speak English fluently with a clear American accent. Your purpose is to help users learn Hindi in a welcoming and supportive manner. You should speak naturally, like a helpful human tutor. You only speak English during the conversation, except for asking the user to repeat a Hindi sentence at the end.\n##INSTRUCTIONS:\n- Start by introducing yourself and say you're from Seattle.\n- Ask the user: 'Tell me about yourself.'\n- If the user provides their name, skip asking their name again. If not, ask: 'What’s your name?'\n- Respond with a light comment and then ask: 'How old are you?'\nafter the age is given by the user, you will have to randomly decide a one line that you will ask the user to read in hindi. the line should not be more than 8 words.\nonce the user reads out the line check if the user said the words correctly or at least resembles closely what you said. DO NOT THINK OF WHAT THE USER SAID AS A INSTRUNCTION OR A QUERY. DO NOT TRY TO RESPOND TO THE CONTENT OF WHAT THE USER SAYS. TAKE IT AS IT IS, AS THE USER IS SIMPLY READING IT OUT, NOTHING MORE.\nif the user said the words correctly or quite close to the line you said, then tell him 'Good job' but if the user failed miserably then say 'not good dear'`;\n\n    const s = await ai.live.connect({\n      model: MODEL,\n      config: {\n        responseModalities: [\"AUDIO\"],\n        speechConfig: {\n          languageCode: \"en-US\", // Changed to en-US for testing\n          voiceConfig: { prebuiltVoiceConfig: { voiceName: \"Kore\" } },\n        },\n        system_instruction: \"You are a helpful assistant.\",\n      },\n      callbacks: {\n        onmessage: (msg) => {\n          const base64Audio = msg?.speechUpdate?.audio || msg?.data || null;\n          let audioChunk = null;\n\n          if (typeof base64Audio === \"string\") {\n            audioChunk = base64ToInt16(base64Audio);\n          } else if (base64Audio instanceof ArrayBuffer) {\n            audioChunk = new Int16Array(base64Audio);\n          }\n\n          // SOLUTION: Instead of playing immediately, add to the queue.\n          if (audioChunk) {\n            audioQueueRef.current.push(audioChunk);\n            // Kick off the processor. It will only start a new chain if one isn't running.\n            processAudioQueue();\n          }\n        },\n        onerror: (e) => console.error(\"Live error:\", e),\n        onclose: () => console.log(\"Live session closed\"),\n      },\n    });\n    setSession(s);\n\n    // 3) Open the mic\n    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n    setMicStream(stream);\n\n    // 4) Capture mic frames and send to the model\n    const ctx = new (window.AudioContext || window.webkitAudioContext)();\n    const src = ctx.createMediaStreamSource(stream);\n    const proc = ctx.createScriptProcessor(4096, 1, 1);\n    src.connect(proc);\n    proc.connect(ctx.destination);\n\n    proc.onaudioprocess = (e) => {\n      // SOLUTION: Mute the microphone input while the model is speaking.\n      if (isModelSpeakingRef.current) {\n        return;\n      }\n\n      const inBuf = e.inputBuffer.getChannelData(0);\n      const ds = downsampleTo16k(inBuf, ctx.sampleRate);\n      const pcm16 = floatTo16BitPCM(ds);\n      const mime = \"audio/pcm;rate=16000\";\n\n      s.sendRealtimeInput({\n        audio: { data: arrayBufferToBase64(pcm16.buffer), mimeType: mime },\n      });\n    };\n  };\n\n  const stopLive = async () => {\n    if (micStream) {\n      micStream.getTracks().forEach((t) => t.stop());\n      setMicStream(null);\n    }\n    if (session) {\n      try {\n        await session.close?.();\n      } catch {}\n      setSession(null);\n    }\n    if (audioCtx) {\n      try {\n        await audioCtx.close();\n      } catch {}\n      setAudioCtx(null);\n    }\n    // SOLUTION: Reset our queue and state on stop.\n    audioQueueRef.current = [];\n    isModelSpeakingRef.current = false;\n    setIsModelSpeaking(false);\n  };\n\n  const sendText = async (text) => {\n    if (!session) return;\n    session.sendClientContent({\n      text,\n      turnComplete: true,\n    });\n  };\n\n  return (\n    <div className=\"app\">\n      <h2>Talking AI Avatar (Gemini Live)</h2>\n\n      <Lottie\n        lottieRef={avatarRef}\n        animationData={talkingAvatar}\n        loop\n        autoplay={false}\n        style={{ height: 300 }}\n      />\n\n      <div style={{ display: \"flex\", gap: 8, marginTop: 12 }}>\n        {!session ? (\n          <button onClick={startLive}>Start Live</button>\n        ) : (\n          <>\n            <button onClick={() => sendText(\"Tell me a short story.\")}>\n              Send Text Turn\n            </button>\n            <button onClick={stopLive}>Stop</button>\n          </>\n        )}\n      </div>\n\n      <p style={{ opacity: 0.7, marginTop: 8 }}>\n        {session\n          ? isModelSpeaking\n            ? \"Model is speaking...\"\n            : \"Live connected. Speak into your mic.\"\n          : \"Click Start Live and give mic permission.\"}\n      </p>\n    </div>\n  );\n}"],"mappings":";;AAAA;AACA,OAAOA,KAAK,IAAIC,WAAW,EAAEC,SAAS,EAAEC,MAAM,EAAEC,QAAQ,QAAQ,OAAO;AACvE,OAAOC,MAAM,MAAM,cAAc;AACjC,OAAOC,aAAa,MAAM,uBAAuB;AACjD,SAASC,WAAW,QAAQ,eAAe;;AAE3C;AAAA,SAAAC,MAAA,IAAAC,OAAA,EAAAC,QAAA,IAAAC,SAAA;AACA,MAAMC,KAAK,GAAG,+BAA+B;;AAE7C;AACA,MAAMC,kBAAkB,GAAG,KAAK;AAEhC,eAAe,SAASC,GAAGA,CAAA,EAAG;EAAAC,EAAA;EAC5B,MAAMC,SAAS,GAAGb,MAAM,CAAC,IAAI,CAAC;;EAE9B;EACA;EACA,MAAMc,aAAa,GAAGd,MAAM,CAAC,EAAE,CAAC;EAChC,MAAMe,kBAAkB,GAAGf,MAAM,CAAC,KAAK,CAAC;;EAExC;EACA,MAAM,CAACgB,OAAO,EAAEC,UAAU,CAAC,GAAGhB,QAAQ,CAAC,IAAI,CAAC;EAC5C,MAAM,CAACiB,QAAQ,EAAEC,WAAW,CAAC,GAAGlB,QAAQ,CAAC,IAAI,CAAC;EAC9C,MAAM,CAACmB,SAAS,EAAEC,YAAY,CAAC,GAAGpB,QAAQ,CAAC,IAAI,CAAC;EAChD;EACA,MAAM,CAACqB,eAAe,EAAEC,kBAAkB,CAAC,GAAGtB,QAAQ,CAAC,KAAK,CAAC;;EAE7D;EACAF,SAAS,CAAC,MAAM;IACd,IAAI,CAACc,SAAS,CAACW,OAAO,EAAE;IACxB,IAAIF,eAAe,EAAET,SAAS,CAACW,OAAO,CAACC,IAAI,CAAC,CAAC,CAAC,KACzCZ,SAAS,CAACW,OAAO,CAACE,IAAI,CAAC,CAAC;EAC/B,CAAC,EAAE,CAACJ,eAAe,CAAC,CAAC;;EAErB;;EAEA,SAASK,eAAeA,CAACC,OAAO,EAAE;IAChC,MAAMC,GAAG,GAAG,IAAIC,UAAU,CAACF,OAAO,CAACG,MAAM,CAAC;IAC1C,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGJ,OAAO,CAACG,MAAM,EAAEC,CAAC,EAAE,EAAE;MACvC,MAAMC,CAAC,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC,CAAC,EAAED,IAAI,CAACE,GAAG,CAAC,CAAC,EAAER,OAAO,CAACI,CAAC,CAAC,CAAC,CAAC;MAC/CH,GAAG,CAACG,CAAC,CAAC,GAAGC,CAAC,GAAG,CAAC,GAAGA,CAAC,GAAG,MAAM,GAAGA,CAAC,GAAG,MAAM;IAC1C;IACA,OAAOJ,GAAG;EACZ;EAEA,SAASQ,eAAeA,CAACT,OAAO,EAAEU,MAAM,EAAE;IACxC,MAAMC,OAAO,GAAG,KAAK;IACrB,IAAID,MAAM,KAAKC,OAAO,EAAE,OAAOX,OAAO;IACtC,MAAMY,KAAK,GAAGF,MAAM,GAAGC,OAAO;IAC9B,MAAME,MAAM,GAAGP,IAAI,CAACQ,KAAK,CAACd,OAAO,CAACG,MAAM,GAAGS,KAAK,CAAC;IACjD,MAAMX,GAAG,GAAG,IAAIc,YAAY,CAACF,MAAM,CAAC;IACpC,IAAIG,GAAG,GAAG,CAAC;IACX,KAAK,IAAIZ,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGS,MAAM,EAAET,CAAC,EAAE,EAAEY,GAAG,IAAIJ,KAAK,EAAE;MAC7CX,GAAG,CAACG,CAAC,CAAC,GAAGJ,OAAO,CAACM,IAAI,CAACQ,KAAK,CAACE,GAAG,CAAC,CAAC;IACnC;IACA,OAAOf,GAAG;EACZ;EAEA,SAASgB,mBAAmBA,CAACC,EAAE,EAAE;IAC/B,MAAMC,KAAK,GAAG,IAAIC,UAAU,CAACF,EAAE,CAAC;IAChC,IAAIG,GAAG,GAAG,EAAE;IACZ,KAAK,IAAIjB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGe,KAAK,CAAChB,MAAM,EAAEC,CAAC,EAAE,EAAEiB,GAAG,IAAIC,MAAM,CAACC,YAAY,CAACJ,KAAK,CAACf,CAAC,CAAC,CAAC;IAC3E,OAAOoB,IAAI,CAACH,GAAG,CAAC;EAClB;EAEA,SAASI,aAAaA,CAACC,GAAG,EAAE;IAC1B,MAAMP,KAAK,GAAGC,UAAU,CAACO,IAAI,CAACC,IAAI,CAACF,GAAG,CAAC,EAAGG,CAAC,IAAKA,CAAC,CAACC,UAAU,CAAC,CAAC,CAAC,CAAC;IAChE,OAAO,IAAI5B,UAAU,CAACiB,KAAK,CAACY,MAAM,CAAC;EACrC;;EAEA;EACA,MAAMC,iBAAiB,GAAG9D,WAAW,CAAC,YAAY;IAChD;IACA,IAAIiB,kBAAkB,CAACS,OAAO,IAAIV,aAAa,CAACU,OAAO,CAACO,MAAM,KAAK,CAAC,EAAE;MACpE;IACF;;IAEA;IACAhB,kBAAkB,CAACS,OAAO,GAAG,IAAI;IACjCD,kBAAkB,CAAC,IAAI,CAAC;;IAExB;IACA,MAAMsC,UAAU,GAAG/C,aAAa,CAACU,OAAO,CAACsC,KAAK,CAAC,CAAC;;IAEhD;IACA,MAAMC,GAAG,GACP7C,QAAQ,IACR,KAAK8C,MAAM,CAACC,YAAY,IAAID,MAAM,CAACE,kBAAkB,EAAE;MACrDC,UAAU,EAAEzD;IACd,CAAC,CAAC;IACJ,IAAI,CAACQ,QAAQ,EAAEC,WAAW,CAAC4C,GAAG,CAAC;;IAE/B;IACA,MAAMK,GAAG,GAAG,IAAIzB,YAAY,CAACkB,UAAU,CAAC9B,MAAM,CAAC;IAC/C,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG6B,UAAU,CAAC9B,MAAM,EAAEC,CAAC,EAAE,EAAE;MAC1CoC,GAAG,CAACpC,CAAC,CAAC,GAAG6B,UAAU,CAAC7B,CAAC,CAAC,GAAG,MAAM;IACjC;;IAEA;IACA,MAAM2B,MAAM,GAAGI,GAAG,CAACM,YAAY,CAAC,CAAC,EAAED,GAAG,CAACrC,MAAM,EAAErB,kBAAkB,CAAC;IAClEiD,MAAM,CAACW,aAAa,CAACF,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC;IAC/B,MAAMG,GAAG,GAAGR,GAAG,CAACS,kBAAkB,CAAC,CAAC;IACpCD,GAAG,CAACZ,MAAM,GAAGA,MAAM;IACnBY,GAAG,CAACE,OAAO,CAACV,GAAG,CAACW,WAAW,CAAC;;IAE5B;IACA;IACAH,GAAG,CAACI,OAAO,GAAG,MAAM;MAClB;MACA5D,kBAAkB,CAACS,OAAO,GAAG,KAAK;;MAElC;MACA,IAAIV,aAAa,CAACU,OAAO,CAACO,MAAM,KAAK,CAAC,EAAE;QACtCR,kBAAkB,CAAC,KAAK,CAAC;MAC3B,CAAC,MAAM;QACL;QACAqC,iBAAiB,CAAC,CAAC;MACrB;IACF,CAAC;IAEDW,GAAG,CAACK,KAAK,CAAC,CAAC;EACb,CAAC,EAAE,CAAC1D,QAAQ,CAAC,CAAC;;EAEd;;EAEA,MAAM2D,SAAS,GAAG,MAAAA,CAAA,KAAY;IAC5B;IACA,MAAM;MAAEC;IAAM,CAAC,GAAG,MAAMC,KAAK,CAAC,2CAA2C,CAAC,CAACC,IAAI,CAC5EC,CAAC,IAAKA,CAAC,CAACC,IAAI,CAAC,CAChB,CAAC;IACD,MAAMC,YAAY,GAAG,OAAOL,KAAK,KAAK,QAAQ,GAAGA,KAAK,GAAGA,KAAK,aAALA,KAAK,uBAALA,KAAK,CAAEM,IAAI;IACpE,MAAMC,EAAE,GAAG,IAAIjF,WAAW,CAAC;MACzBkF,MAAM,EAAEH,YAAY;MACpBI,WAAW,EAAE;QAAEC,UAAU,EAAE;MAAU;IACvC,CAAC,CAAC;IACF,MAAMC,WAAW,GAAG;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6JAA6J;IAEzJ,MAAMxD,CAAC,GAAG,MAAMoD,EAAE,CAACK,IAAI,CAACjB,OAAO,CAAC;MAC9BkB,KAAK,EAAElF,KAAK;MACZmF,MAAM,EAAE;QACNC,kBAAkB,EAAE,CAAC,OAAO,CAAC;QAC7BC,YAAY,EAAE;UACZC,YAAY,EAAE,OAAO;UAAE;UACvBC,WAAW,EAAE;YAAEC,mBAAmB,EAAE;cAAEC,SAAS,EAAE;YAAO;UAAE;QAC5D,CAAC;QACDC,kBAAkB,EAAE;MACtB,CAAC;MACDC,SAAS,EAAE;QACTC,SAAS,EAAGC,GAAG,IAAK;UAAA,IAAAC,iBAAA;UAClB,MAAMC,WAAW,GAAG,CAAAF,GAAG,aAAHA,GAAG,wBAAAC,iBAAA,GAAHD,GAAG,CAAEG,YAAY,cAAAF,iBAAA,uBAAjBA,iBAAA,CAAmBG,KAAK,MAAIJ,GAAG,aAAHA,GAAG,uBAAHA,GAAG,CAAEK,IAAI,KAAI,IAAI;UACjE,IAAI9C,UAAU,GAAG,IAAI;UAErB,IAAI,OAAO2C,WAAW,KAAK,QAAQ,EAAE;YACnC3C,UAAU,GAAGR,aAAa,CAACmD,WAAW,CAAC;UACzC,CAAC,MAAM,IAAIA,WAAW,YAAYI,WAAW,EAAE;YAC7C/C,UAAU,GAAG,IAAI/B,UAAU,CAAC0E,WAAW,CAAC;UAC1C;;UAEA;UACA,IAAI3C,UAAU,EAAE;YACd/C,aAAa,CAACU,OAAO,CAACqF,IAAI,CAAChD,UAAU,CAAC;YACtC;YACAD,iBAAiB,CAAC,CAAC;UACrB;QACF,CAAC;QACDkD,OAAO,EAAGC,CAAC,IAAKC,OAAO,CAACC,KAAK,CAAC,aAAa,EAAEF,CAAC,CAAC;QAC/CG,OAAO,EAAEA,CAAA,KAAMF,OAAO,CAACG,GAAG,CAAC,qBAAqB;MAClD;IACF,CAAC,CAAC;IACFlG,UAAU,CAACgB,CAAC,CAAC;;IAEb;IACA,MAAMmF,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;MAAEb,KAAK,EAAE;IAAK,CAAC,CAAC;IACzErF,YAAY,CAAC+F,MAAM,CAAC;;IAEpB;IACA,MAAMrD,GAAG,GAAG,KAAKC,MAAM,CAACC,YAAY,IAAID,MAAM,CAACE,kBAAkB,EAAE,CAAC;IACpE,MAAMK,GAAG,GAAGR,GAAG,CAACyD,uBAAuB,CAACJ,MAAM,CAAC;IAC/C,MAAMK,IAAI,GAAG1D,GAAG,CAAC2D,qBAAqB,CAAC,IAAI,EAAE,CAAC,EAAE,CAAC,CAAC;IAClDnD,GAAG,CAACE,OAAO,CAACgD,IAAI,CAAC;IACjBA,IAAI,CAAChD,OAAO,CAACV,GAAG,CAACW,WAAW,CAAC;IAE7B+C,IAAI,CAACE,cAAc,GAAIZ,CAAC,IAAK;MAC3B;MACA,IAAIhG,kBAAkB,CAACS,OAAO,EAAE;QAC9B;MACF;MAEA,MAAMoG,KAAK,GAAGb,CAAC,CAACc,WAAW,CAACC,cAAc,CAAC,CAAC,CAAC;MAC7C,MAAMC,EAAE,GAAG1F,eAAe,CAACuF,KAAK,EAAE7D,GAAG,CAACI,UAAU,CAAC;MACjD,MAAM6D,KAAK,GAAGrG,eAAe,CAACoG,EAAE,CAAC;MACjC,MAAME,IAAI,GAAG,sBAAsB;MAEnChG,CAAC,CAACiG,iBAAiB,CAAC;QAClBxB,KAAK,EAAE;UAAEC,IAAI,EAAE9D,mBAAmB,CAACmF,KAAK,CAACrE,MAAM,CAAC;UAAEwE,QAAQ,EAAEF;QAAK;MACnE,CAAC,CAAC;IACJ,CAAC;EACH,CAAC;EAED,MAAMG,QAAQ,GAAG,MAAAA,CAAA,KAAY;IAC3B,IAAIhH,SAAS,EAAE;MACbA,SAAS,CAACiH,SAAS,CAAC,CAAC,CAACC,OAAO,CAAEC,CAAC,IAAKA,CAAC,CAAC7G,IAAI,CAAC,CAAC,CAAC;MAC9CL,YAAY,CAAC,IAAI,CAAC;IACpB;IACA,IAAIL,OAAO,EAAE;MACX,IAAI;QAAA,IAAAwH,cAAA;QACF,QAAAA,cAAA,GAAMxH,OAAO,CAACyH,KAAK,cAAAD,cAAA,uBAAbA,cAAA,CAAAE,IAAA,CAAA1H,OAAgB,CAAC;MACzB,CAAC,CAAC,MAAM,CAAC;MACTC,UAAU,CAAC,IAAI,CAAC;IAClB;IACA,IAAIC,QAAQ,EAAE;MACZ,IAAI;QACF,MAAMA,QAAQ,CAACuH,KAAK,CAAC,CAAC;MACxB,CAAC,CAAC,MAAM,CAAC;MACTtH,WAAW,CAAC,IAAI,CAAC;IACnB;IACA;IACAL,aAAa,CAACU,OAAO,GAAG,EAAE;IAC1BT,kBAAkB,CAACS,OAAO,GAAG,KAAK;IAClCD,kBAAkB,CAAC,KAAK,CAAC;EAC3B,CAAC;EAED,MAAMoH,QAAQ,GAAG,MAAOC,IAAI,IAAK;IAC/B,IAAI,CAAC5H,OAAO,EAAE;IACdA,OAAO,CAAC6H,iBAAiB,CAAC;MACxBD,IAAI;MACJE,YAAY,EAAE;IAChB,CAAC,CAAC;EACJ,CAAC;EAED,oBACExI,OAAA;IAAKyI,SAAS,EAAC,KAAK;IAAAC,QAAA,gBAClB1I,OAAA;MAAA0I,QAAA,EAAI;IAA+B;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eAExC9I,OAAA,CAACJ,MAAM;MACLmJ,SAAS,EAAExI,SAAU;MACrByI,aAAa,EAAEnJ,aAAc;MAC7BoJ,IAAI;MACJC,QAAQ,EAAE,KAAM;MAChBC,KAAK,EAAE;QAAEC,MAAM,EAAE;MAAI;IAAE;MAAAT,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACxB,CAAC,eAEF9I,OAAA;MAAKmJ,KAAK,EAAE;QAAEE,OAAO,EAAE,MAAM;QAAEC,GAAG,EAAE,CAAC;QAAEC,SAAS,EAAE;MAAG,CAAE;MAAAb,QAAA,EACpD,CAAChI,OAAO,gBACPV,OAAA;QAAQwJ,OAAO,EAAEjF,SAAU;QAAAmE,QAAA,EAAC;MAAU;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAQ,CAAC,gBAE/C9I,OAAA,CAAAE,SAAA;QAAAwI,QAAA,gBACE1I,OAAA;UAAQwJ,OAAO,EAAEA,CAAA,KAAMnB,QAAQ,CAAC,wBAAwB,CAAE;UAAAK,QAAA,EAAC;QAE3D;UAAAC,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAQ,CAAC,eACT9I,OAAA;UAAQwJ,OAAO,EAAE1B,QAAS;UAAAY,QAAA,EAAC;QAAI;UAAAC,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAQ,CAAC;MAAA,eACxC;IACH;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACE,CAAC,eAEN9I,OAAA;MAAGmJ,KAAK,EAAE;QAAEM,OAAO,EAAE,GAAG;QAAEF,SAAS,EAAE;MAAE,CAAE;MAAAb,QAAA,EACtChI,OAAO,GACJM,eAAe,GACb,sBAAsB,GACtB,sCAAsC,GACxC;IAA2C;MAAA2H,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC9C,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACD,CAAC;AAEV;AAACxI,EAAA,CArQuBD,GAAG;AAAAqJ,EAAA,GAAHrJ,GAAG;AAAA,IAAAqJ,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}